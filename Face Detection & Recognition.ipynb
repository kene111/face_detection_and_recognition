{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DETECTING AND GENERATING OF IMAGE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(image, p_id, image_id):\n",
    "    cv2.imwrite('face_data/user.'+str(p_id)+'.'+str(image_id)+'.jpg',image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary_1(image, classifier, scalefactor, min_neighbors, color, text):\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_scale, scalefactor, min_neighbors)\n",
    "    coordinates = []\n",
    "    \n",
    "    for (x, y, w, h) in features:\n",
    "        cv2.rectangle(image, (x,y),(x+w, y+h), color, 1)        \n",
    "        cv2.putText(image, text, (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
    "        coordinates = [x, y, w, h]\n",
    "        \n",
    "    return coordinates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_1(image, facecascade, image_id):\n",
    "    color = {'blue':(0,0,255), 'red':(255,0,0), 'green':(0,255,0), 'white':(255,255,255)}\n",
    "    coordinate = draw_boundary_1(image, facecascade,1.1, 10, color['white'], 'FACE')\n",
    "    \n",
    "    if len(coordinate)==4:\n",
    "        area_of_focus = image[coordinate[1]:coordinate[1]+coordinate[3], coordinate[0]:coordinate[0]+coordinate[2]]\n",
    "               \n",
    "        p_id = 1\n",
    "        generate_dataset(area_of_focus, p_id, image_id)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_2(image, facecascade, image_id):\n",
    "    color = {'blue':(0,0,255), 'red':(255,0,0), 'green':(0,255,0), 'white':(255,255,255)}\n",
    "    coordinate = draw_boundary_1(image, facecascade,1.1, 10, color['red'], 'FACE')\n",
    "    \n",
    "    if len(coordinate)==4:\n",
    "        area_of_focus = image[coordinate[1]:coordinate[1]+coordinate[3], coordinate[0]:coordinate[0]+coordinate[2]]\n",
    "               \n",
    "        p_id = 2\n",
    "        generate_dataset(area_of_focus, p_id, image_id)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture  = cv2.VideoCapture(0) #if using an external webcam type in -1 inplace of 0\n",
    "image_id = 0\n",
    "\n",
    "while True:\n",
    "    _ ,image = video_capture.read()\n",
    "    image = detect_1(image, facecascade, image_id)\n",
    "    #image = recognize(image, clf, facecascade)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    image_id += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'): # to break loop press e\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture  = cv2.VideoCapture(0) #if using an external webcam type in -1 inplace of 0\n",
    "image_id = 0\n",
    "\n",
    "while True:\n",
    "    _ ,image = video_capture.read()\n",
    "    image = detect_2(image, facecascade, image_id)\n",
    "    #image = recognize(image, clf, facecascade)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    image_id += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'): # to break loop press e\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE TRAINING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(data_dir):\n",
    "        path = [os.path.join(data_dir, f) for f in os.listdir(data_dir)]\n",
    "        faces = []\n",
    "        ids = []\n",
    "        \n",
    "        for image_ in path:\n",
    "            img = Image.open(image_).convert('L')\n",
    "            image_numpy = np.array(img, 'uint8')\n",
    "            #facez = classifier.detectMultiScale(image_numpy, scalefactor, min_neighbors)\n",
    "            id_ = int(os.path.split(image_)[1].split(\".\")[1])\n",
    "            \n",
    "            faces.append(image_numpy)\n",
    "            ids.append(id_)\n",
    "            \n",
    "        ids= np.array(ids)\n",
    "        \n",
    "        clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "        clf.train(faces, ids)\n",
    "        clf.write('classifier.yml')\n",
    "            \n",
    "train_classifier('face_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMAGE DETECTION/PREDICTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "facecascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')\n",
    "clf = cv2.face.LBPHFaceRecognizer_create()\n",
    "clf.read('classifier.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_boundary(image, classifier, scalefactor, min_neighbors, color, text, clf):\n",
    "    gray_scale = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    features = classifier.detectMultiScale(gray_scale, scalefactor, min_neighbors)\n",
    "    coordinates = []\n",
    "    \n",
    "    for (x, y, w, h) in features:\n",
    "        cv2.rectangle(image, (x,y),(x+w, y+h), color, 1)\n",
    "        id_, _= clf.predict(gray_scale[y:y+h, x:x+w])\n",
    "        \n",
    "        if id_ == 1:\n",
    "            cv2.putText(image, 'xxxx', (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
    "            coordinates = [x, y, w, h]\n",
    "        elif id_ == 2 :\n",
    "            cv2.putText(image, 'yyyy', (x, y-4), cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)\n",
    "            coordinates = [x, y, w, h]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    return coordinates\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize(image, clf,facecascade ):\n",
    "    color = {'blue':(0,0,255), 'red':(255,0,0), 'green':(0,255,0), 'white':(255,255,255)}\n",
    "    coordinate = draw_boundary(image,facecascade,1.1, 10, color['white'], 'FACE', clf)\n",
    "    return image\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_capture  = cv2.VideoCapture(0) #if using an external webcam type in -1 inplace of 0\n",
    "image_id = 0\n",
    "\n",
    "while True:\n",
    "    _ ,image = video_capture.read()\n",
    "    #image = detect(image, facecascade, image_id)\n",
    "    image = recognize(image, clf, facecascade)\n",
    "    cv2.imshow('Face Detection', image)\n",
    "    image_id += 1\n",
    "    if cv2.waitKey(1) & 0xFF == ord('e'): # to break loop press e\n",
    "        break\n",
    "        \n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
